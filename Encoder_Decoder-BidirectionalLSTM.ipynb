{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "from faker import Faker\n",
    "import babel\n",
    "from babel.dates import format_date\n",
    "import os\n",
    "import tensorflow.contrib.legacy_seq2seq as seq2seq\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = Faker()\n",
    "fake.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "FORMATS=['short',\n",
    "        'medium',\n",
    "        'long',\n",
    "        'full',\n",
    "        'd MMM YYY',\n",
    "        'd MMMM YYY',\n",
    "        'dd MMM YYY',\n",
    "        'd MMM, YYY',\n",
    "        'd MMMM, YYY',\n",
    "        'dd, MMM YYY',\n",
    "        'd MM YY',\n",
    "        'd MMMM YYY',\n",
    "        'MMMM d YYY',\n",
    "        'MMMM d, YYY',\n",
    "        'dd.MM.YY',\n",
    "           ]\n",
    "\n",
    "# change this if you want it to work with only a single language\n",
    "LOCALES = babel.localedata.locale_identifiers()\n",
    "LOCALES = [lang for lang in LOCALES if 'en' in str(lang)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_date():\n",
    "    \"\"\"\n",
    "        Creates some fake dates \n",
    "        :returns: tuple containing \n",
    "                  1. human formatted string\n",
    "                  2. machine formatted string\n",
    "                  3. date object.\n",
    "    \"\"\"\n",
    "    dt = fake.date_object()\n",
    "\n",
    "    # wrapping this in a try catch because\n",
    "    # the locale 'vo' and format 'full' will fail\n",
    "    try:\n",
    "        human = format_date(dt,\n",
    "                            format=random.choice(FORMATS),\n",
    "                            locale=random.choice(LOCALES))\n",
    "\n",
    "        case_change = random.randint(0,3) # 1/2 chance of case change\n",
    "        if case_change == 1:\n",
    "            human = human.upper()\n",
    "        elif case_change == 2:\n",
    "            human = human.lower()\n",
    "\n",
    "        machine = dt.isoformat()\n",
    "    except AttributeError as e:\n",
    "        return None, None, None\n",
    "\n",
    "    return human, machine #, dt\n",
    "\n",
    "data = [create_date() for _ in range(50000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('7 07 13', '2013-07-07'),\n",
       " ('30 JULY 1977', '1977-07-30'),\n",
       " ('Tuesday, 14 September 1971', '1971-09-14'),\n",
       " ('18 09 88', '1988-09-18'),\n",
       " ('31, Aug 1986', '1986-08-31')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [x for x,y in data]\n",
    "y = [y for x,y in data]\n",
    "\n",
    "u_charactersX = set(' '.join(x))\n",
    "character2numX = dict(zip(u_charactersX,range(len(u_charactersX))))\n",
    "\n",
    "u_charactersY = set(' '.join(y))\n",
    "character2numY = dict(zip(u_charactersY,range(len(u_charactersY))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "character2numX['<PAD>']=len(character2numX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num2charx = dict(zip(character2numX.values(),character2numX.keys()))\n",
    "max_len = max([len(date) for date in x])\n",
    "x = np.array([[character2numX['<PAD>']] * (max_len-len(date))+[character2numX[x_] for x_ in date] for date in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "character2numY['<GO>']=len(character2numY)\n",
    "max_len = max([len(date) for date in y])\n",
    "y = np.array([[character2numY['<GO>']] + [character2numY[y_] for y_ in date] for date in y])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num2chary = dict(zip(character2numY.values(),character2numY.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_seq_length= len(x[0])\n",
    "y_seq_length=len(y[0])-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_batch(x,y,batch_size):\n",
    "    shuffle = np.random.permutation(len(x))\n",
    "    start = 0\n",
    "    x = x[shuffle]\n",
    "    y = y[shuffle]\n",
    "    \n",
    "    while start+batch_size <= len(x):\n",
    "        yield x[start:start+batch_size],y[start:start+batch_size]\n",
    "        start +=batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 20\n",
    "batch_size=128\n",
    "nodes =32\n",
    "embedding = 10\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# Tensor where we will feed the data into graph\n",
    "inputs = tf.placeholder(tf.int32,[None,x_seq_length],name='inputs')\n",
    "outputs = tf.placeholder(tf.int32,[None,None],name='outputs')\n",
    "targets = tf.placeholder(tf.int32,[None,None],name='targets')\n",
    "\n",
    "# Embedding layers\n",
    "\n",
    "input_embedding = tf.Variable(tf.random_uniform([len(character2numX),embedding],-1.0,1.0),name='x_embeding')\n",
    "output_embedding = tf.Variable(tf.random_uniform([len(character2numY),embedding],-1.0,1.0),name='y_embeding')\n",
    "\n",
    "date_input_embed = tf.nn.embedding_lookup(input_embedding, inputs)\n",
    "date_output_embed = tf.nn.embedding_lookup(output_embedding, outputs)\n",
    "\n",
    "with tf.variable_scope(\"encoding\") as encoding_scope:\n",
    "    lstm_enc_fw = tf.contrib.rnn.BasicLSTMCell(nodes)\n",
    "    lstm_enc_bw = tf.contrib.rnn.BasicLSTMCell(nodes)\n",
    "    #_, last_state = tf.nn.dynamic_rnn(lstm_enc, inputs=date_input_embed, dtype=tf.float32)\n",
    "    ((lstm_fw_out,lstm_bw_out),(lstm_fw_final,lstm_bw_final))=tf.nn.bidirectional_dynamic_rnn(cell_fw=lstm_enc_fw,\n",
    "                                                                                             cell_bw=lstm_enc_bw,\n",
    "                                                                                             inputs=date_input_embed,\n",
    "                                                                                             dtype=tf.float32)\n",
    "    enc_fin_c = tf.concat((lstm_fw_final.c,lstm_bw_final.c),1)\n",
    "    enc_fin_h = tf.concat((lstm_fw_final.h,lstm_bw_final.h),1)\n",
    "    last_state = tf.contrib.rnn.LSTMStateTuple(c=enc_fin_c,h=enc_fin_h)\n",
    "\n",
    "with tf.variable_scope(\"decoding\") as decoding_scope:\n",
    "    lstm_dec = tf.contrib.rnn.BasicLSTMCell(nodes*2)\n",
    "    dec_outputs, _ = tf.nn.dynamic_rnn(lstm_dec, inputs=date_output_embed, initial_state=last_state)\n",
    "    \n",
    "logits = tf.layers.dense(dec_outputs, units=len(character2numY)) \n",
    "with tf.name_scope(\"optimization\"):\n",
    "    # Loss function\n",
    "    loss = tf.contrib.seq2seq.sequence_loss(logits, targets, tf.ones([batch_size, y_seq_length]))\n",
    "    # Optimizer\n",
    "    optimizer = tf.train.RMSPropOptimizer(1e-3).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, 64]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_outputs.get_shape().as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 64]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_state[0].get_shape().as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 29, 10]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "date_input_embed.get_shape().as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 29]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.get_shape().as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(None), Dimension(13)])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 Loss:  0.995 Accuracy: 0.6297 Epoch duration:  8.549s\n",
      "Epoch   1 Loss:  0.684 Accuracy: 0.7406 Epoch duration:  7.962s\n",
      "Epoch   2 Loss:  0.527 Accuracy: 0.8156 Epoch duration:  7.753s\n",
      "Epoch   3 Loss:  0.450 Accuracy: 0.8305 Epoch duration:  7.400s\n",
      "Epoch   4 Loss:  0.394 Accuracy: 0.8461 Epoch duration:  7.587s\n",
      "Epoch   5 Loss:  0.315 Accuracy: 0.8812 Epoch duration:  7.831s\n",
      "Epoch   6 Loss:  0.277 Accuracy: 0.9047 Epoch duration:  8.463s\n",
      "Epoch   7 Loss:  0.191 Accuracy: 0.9383 Epoch duration:  7.849s\n",
      "Epoch   8 Loss:  0.152 Accuracy: 0.9539 Epoch duration:  7.381s\n",
      "Epoch   9 Loss:  0.160 Accuracy: 0.9477 Epoch duration:  7.323s\n",
      "Epoch  10 Loss:  0.117 Accuracy: 0.9602 Epoch duration:  7.355s\n",
      "Epoch  11 Loss:  0.090 Accuracy: 0.9711 Epoch duration:  7.419s\n",
      "Epoch  12 Loss:  0.167 Accuracy: 0.9461 Epoch duration:  8.140s\n",
      "Epoch  13 Loss:  0.038 Accuracy: 0.9930 Epoch duration:  8.476s\n",
      "Epoch  14 Loss:  0.034 Accuracy: 0.9922 Epoch duration:  8.687s\n",
      "Epoch  15 Loss:  0.048 Accuracy: 0.9914 Epoch duration:  8.937s\n",
      "Epoch  16 Loss:  0.030 Accuracy: 0.9953 Epoch duration:  9.237s\n",
      "Epoch  17 Loss:  0.018 Accuracy: 0.9984 Epoch duration:  9.037s\n",
      "Epoch  18 Loss:  0.016 Accuracy: 0.9969 Epoch duration:  8.872s\n",
      "Epoch  19 Loss:  0.011 Accuracy: 0.9969 Epoch duration:  9.000s\n"
     ]
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "epochs = 20\n",
    "for epoch_i in range(epochs):\n",
    "    start_time = time.time()\n",
    "    for batch_i, (source_batch, target_batch) in enumerate(gen_batch(X_train, y_train, batch_size)):\n",
    "        _, batch_loss, batch_logits = sess.run([optimizer, loss, logits],\n",
    "            feed_dict = {inputs: source_batch,\n",
    "             outputs: target_batch[:, :-1],\n",
    "             targets: target_batch[:, 1:]})\n",
    "    accuracy = np.mean(batch_logits.argmax(axis=-1) == target_batch[:,1:])\n",
    "    print('Epoch {:3} Loss: {:>6.3f} Accuracy: {:>6.4f} Epoch duration: {:>6.3f}s'.format(epoch_i, batch_loss, accuracy, time.time() - start_time)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set is:  0.988\n"
     ]
    }
   ],
   "source": [
    "source_batch, target_batch = next(gen_batch(X_test, y_test, batch_size))\n",
    "dec_input = np.zeros((len(source_batch), 1)) + character2numY['<GO>']\n",
    "for i in range(y_seq_length):\n",
    "    batch_logits = sess.run(logits,\n",
    "                feed_dict = {inputs: source_batch,\n",
    "                 outputs: dec_input})\n",
    "    prediction = batch_logits[:,-1].argmax(axis=-1)\n",
    "    dec_input = np.hstack([dec_input, prediction[:,None]])\n",
    "    \n",
    "print('Accuracy on test set is: {:>6.3f}'.format(np.mean(dec_input == target_batch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 08 98 => 1998-08-10\n",
      "29, may 1990 => 1990-05-29\n",
      "20 jul 1970 => 1970-07-20\n",
      "15 september, 2002 => 2002-09-15\n",
      "15 09 15 => 2015-09-15\n",
      "01/09/2002 => 2002-01-09\n",
      "24.11.91 => 1991-11-24\n",
      "13 SEPTEMBER 2000 => 2000-09-13\n",
      "12, Sep 1993 => 1993-09-12\n",
      "march 10 2007 => 2007-03-10\n"
     ]
    }
   ],
   "source": [
    "num_preds = 10\n",
    "source_chars = [[num2charx[l] for l in sent if num2charx[l]!=\"<PAD>\"] for sent in source_batch[:num_preds]]\n",
    "dest_chars = [[num2chary[l] for l in sent] for sent in dec_input[:num_preds,1:]]\n",
    "\n",
    "for date_in, date_out in zip(source_chars, dest_chars):\n",
    "    print(''.join(date_in)+' => '+''.join(date_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59,\n",
       "        59, 59, 23, 23,  7, 37, 20, 28,  7, 27,  1,  1, 19],\n",
       "       [59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59,\n",
       "         1,  7, 50, 52, 48, 52, 15, 31,  7, 23, 32, 27, 27]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_batch[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 10)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_input[:2,1:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
